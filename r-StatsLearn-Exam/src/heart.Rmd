---
title: "Heart disease dataset"
output: html_document
date: "2024-05-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("utils.R")

plots.dir <- "../plots/"
```

```{r}
library(RColorBrewer)
```

```{r}

```


## Dataset

Binary classification problem
- No disease
- Disease

```{r}
dat <- read.csv("../data/heart.csv")

target <- 14
dataset.distrib(dat[,target])
```

- age
- sex
- chest pain type (4 values)
- resting blood pressure
- serum cholestoral in mg/dl
- fasting blood sugar > 120 mg/dl (true or false)
- resting electrocardiographic results (values 0,1,2)
- maximum heart rate achieved
- exercise induced angina (yes or no)
- oldpeak = ST depression induced by exercise relative to rest
- the slope of the peak exercise ST segment
- number of major vessels (0-3) colored by flourosopy
- thal: 0 = normal; 1 = fixed defect; 2 = reversable defect

```{r}
boxplot(scale(dat[,-target]))

summary(dat[,-target])
```

```{r}
IQR(scale(heart$age))
quantile(scale(heart$age), probs=c(0.25,0.75))
```

```{r}
boxplot.stats(scale(heart$chol))$out
```

```{r}
heatmap(cor(heart[,-target]), Colv=NA, Rowv=NA)
```


```{r}
n <- nrow(dat)

set.seed(111)
train.idx <- sample(n, n - floor(n / 3), replace=FALSE)

train <- dat[train.idx,]
test <- dat[-train.idx,]
```



## Clustering

```{r}
set.seed(111)
heart.clust <- kmeans(heart[,-target], 2, nstart=20)
```



## Logistic regression

```{r}
library(glmnet)
```

### Ridge regression

```{r}
logist.reg <- cv.glmnet(model.matrix( ~ . -1, train[,-target]), as.factor(train[,target]),
                     intercept=TRUE, family="binomial", alpha=0)
```

```{r}
plot(logist.reg)
```

```{r}
first.metrics(2*train$target-1,
              2*as.numeric(predict(logist.reg, newx=model.matrix(~.-1, train[,-target]), type="class", s="lambda.min"))-1,
              2*test$target-1,
              2*as.numeric(predict(logist.reg, newx=model.matrix(~.-1, test[,-target]), type="class", s="lambda.min"))-1)
```



## Decision tree

```{r}
library(rpart)
library(rpart.plot)
```

```{r}
tree <- rpart::rpart(target ~ ., data=train, method="class",
                     control=rpart.control(minsplit=20, cp=0, xval=5))

mincp <- tree$cptable[which.min(tree$cptable[,"xerror"]), "CP"]

tree.pr <- rpart::prune(tree, cp=mincp)

plotcp(tree)
mincp
```

Grown tree

```{r}
first.metrics(2*train$target-1, 2*as.numeric(predict(tree, type="class"))-3,
              2*test$target-1, 2*as.numeric(predict(tree, type="class", newdata=test[,-target]))-3)

paste0("Terminal nodes: ", sum(tree$frame$var == "<leaf>"))
```

Pruned tree

```{r}
rpart.plot(tree.pr)


first.metrics(2*train$target-1, 2*as.numeric(predict(tree.pr, type="class"))-3,
              2*test$target-1, 2*as.numeric(predict(tree.pr, type="class", newdata=test[,-target]))-3)

paste0("Terminal nodes: ", sum(tree.pr$frame$var == "<leaf>"))
```



## Random forest



## Tree boosting
















