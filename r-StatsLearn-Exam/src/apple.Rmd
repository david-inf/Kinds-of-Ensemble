---
title: "Heart disease dataset"
output: html_document
date: "2024-05-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("utils.R")

plots.dir <- "../plots/"
colors.biasvar <- c("#34558b", "#800080")
```

```{r}
library(RColorBrewer)
library(ggplot2)
```

```{r}

```


## Dataset

Binary classification problem
- good (1)
- bad (0)

```{r}
dat <- read.csv("../data/apple_quality.csv")
dat <- dat[-nrow(dat),-1]
names(dat)[ncol(dat)] <- "Outcome"
target <- which(colnames(dat) == "Outcome")
dat <- na.omit(dat)

# consider changing to {0,1}
dat$Outcome[dat$Outcome == "bad"] <- 0
dat$Outcome[dat$Outcome == "good"] <- 1
dat$Outcome <- as.numeric(dat$Outcome)
# dat$Outcome <- as.factor(dat$Outcome)
dat$Acidity <- as.numeric(dat$Acidity)

target <- 8
dataset.distrib(dat[,target])
```

```{r}
sum(duplicated(dat))
```

- **Size**: size of the apple
- **Weight**: weight of the apple
- **Sweetness**: how sweet an apple is (Grado di dolcezza del frutto (concentrazione di zuccheri))
- **Crunchiness**: how crisp the apple is (Croccantezza sulla base della consistenza del frutto)
- **Juiciness**: how juicy an apple is (Succosità)
- **Ripeness**: how ripe an apple is (Stato di deperibilità del frutto, quanto è maturo)
- **Acidity**: how acid an apple is (Acidità (contenuto e composizione di acidi organici))
- **Quality**: the quality is *good* or *bad*

```{r}
boxplot(scale(dat[,-target]))

summary(dat[,-target])

for (i in 1:(ncol(dat)-1)) {
  print(paste(names(dat)[i], sd(dat[,i])))
}

manyhist(dat[,1:4])
manyhist(dat[,5:7])
```

```{r}
IQR(scale(heart$age))
quantile(scale(heart$age), probs=c(0.25,0.75))
```

```{r}
boxplot.stats(scale(heart$chol))$out
```

```{r}
heatmap(cor(dat[,-target]), Colv=NA, Rowv=NA)
```

### Train-test split

```{r}
n <- nrow(dat)

set.seed(111)
train.idx <- sample(n, n - floor(n / 3), replace=FALSE)

dat.train <- dat[train.idx,]
dat.test <- dat[-train.idx,]
```



## Performance

```{r}

```




## Logistic regression

```{r}
library(glmnet)
```

### Ridge regression

```{r}
logist.reg <- cv.glmnet(model.matrix( ~ . -1, dat.train[,-target]),
                        as.factor(dat.train[,target]),
                        intercept=TRUE, family="binomial", alpha=0)
```

```{r}
print(logist.reg)

paste("Best lambda", logist.reg$lambda.min)
```

```{r}
plot(logist.reg)

plot(logist.reg$glmnet.fit, xvar="lambda", lwd=3)
abline(v=logist.reg$lambda.min, lty=2, lwd=2)
```

```{r}
first.metrics(dat.train[,target], predict(logist.reg, newx=model.matrix(~.-1, dat.train[,-target]),
                                    type="class", s="lambda.min"),
              dat.test[,target], predict(logist.reg, newx=model.matrix(~.-1, dat.test[,-target]),
                                         type="class", s="lambda.min"))
```


### Elastic net regression

```{r}
logist.net <- cv.glmnet(model.matrix( ~ . -1, dat.train[,-target]),
                        as.factor(dat.train[,target]),
                        intercept=TRUE, family="binomial", alpha=0.5)
```

```{r}
print(logist.net)

paste("Best lambda", logist.net$lambda.min)
```

```{r}
plot(logist.net)

plot(logist.net$glmnet.fit, xvar="lambda", lwd=3)
abline(v=log(logist.net$lambda.1se), lty=2, lwd=2)
# legend("topright", legend=rownames(logist.net$glmnet.fit$beta), col=)
```

```{r}
first.metrics(dat.train[,target], predict(logist.net, newx=model.matrix(~.-1, dat.train[,-target]),
                                    type="class", s="lambda.min"),
              dat.test[,target], predict(logist.net, newx=model.matrix(~.-1, dat.test[,-target]),
                                         type="class", s="lambda.min"))
```


## kNN

k-nearest neighbor classifier

```{r}
library(FNN)
```

### Model selection

Choose optimal k

```{r}
knn.err <- myknn.cv(dat.train, 5, target)

k.cross <- which.min(knn.err[,2])
paste("Neighbors:", k.cross)
```

```{r}
# pdf("./plots/biasvar-knn-apple.pdf")
matplot(knn.err, type=c("l", "l"), lty=c(1, 1), lwd=3, col=colors.biasvar,
        xlab="Neighbors", ylab="Error rate", main="Bias-Variance tradeoff")

abline(v=k.cross, lty=2, lwd=2)

legend("bottomright", legend=c("Train", "CV", paste0("k*=", k.cross)),
       col=c(colors.biasvar, "black"),
       lty=c(1, 1, 2), lwd=3, cex=1.5, bg="white")
# dev.off()
```

### Final model

```{r}
knn.train <- FNN::knn(train=dat.train[,-target], test=dat.train[,-target],
                    cl=dat.train[,target], k=k.cross)

knn.test <- FNN::knn(train=dat.train[,-target], test=dat.test[,-target],
                     cl=dat.train[,target], k=k.cross)
```

```{r}
first.metrics(dat.train[,target], knn.train,
              dat.test[,target], knn.test)
```


## Decision tree

Decision tree classifier

```{r}
library(rpart)
library(rpart.plot)
```

### Model selection

```{r}
set.seed(111)
tree <- rpart::rpart(Outcome ~ ., data=dat.train, method="class",
                     control=rpart.control(minsplit=20, cp=0, xval=5))

mincp <- tree$cptable[which.min(tree$cptable[,"xerror"]), "CP"]
paste0("Optimal cp: ", mincp)
```

Diagnostic

```{r}
# pdf("./plots/cp-tree-apple.pdf")
plotcp(tree)
abline(v=which.min(tree$cptable[,"xerror"]), lty=2, col="#B45173", lwd=2)
# dev.off()
```

Grown tree metrics

```{r}
first.metrics(dat.train$Outcome, predict(tree, type="class"),
              dat.test$Outcome, predict(tree, type="class", newdata=dat.test[,-target]))

paste0("Terminal nodes: ", sum(tree$frame$var == "<leaf>"))
```

### Final model

Pruned tree

```{r}
tree.pr <- rpart::prune(tree, cp=mincp)

tree.err <- sum(1 - (predict(tree.pr, type="class", newdata=dat.test) == dat.test[,target])) / nrow(dat.test)

# rpart.plot(tree.pr)

first.metrics(dat.train$Outcome, predict(tree.pr, type="class"),
              dat.test$Outcome, predict(tree.pr, type="class", newdata=dat.test[,-target]))

paste0("Terminal nodes: ", sum(tree.pr$frame$var == "<leaf>"))
```

C'è overfitting ma non troppo


## Random forest

```{r}
library(randomForest)
```

### Grow the forest

```{r}
set.seed(111)
rf.grown <- randomForest(x=dat.train[,-target], y=as.factor(dat.train[,target]),
                         ntree=500, importance=TRUE)

rf.ntree <- which.min(rf.grown$err.rate[,"OOB"])

paste0("Grown forest trees: ", rf.grown$ntree)
paste0("Optimal forest trees: ", rf.ntree)
paste0("mtry: ", rf.grown$mtry)
print(rf.grown$confusion)
```

Diagnostic

```{r}
plot(rf.grown, lty=c(1,1,1), lwd=3)
abline(v=rf.ntree, lwd=3, lty=2)

rf.palette <- colorRampPalette(brewer.pal(5, "Set1"))(4)

# pdf("./plots/biasvar-rf-apple.pdf")
plot(seq(rf.grown$ntree), rf.grown$err.rate[,"OOB"], type="l", lwd=3,
     xlab="ntree", ylab="OOB error", col=rf.palette[1],
     main="Bias-Variance tradeoff", cex.main=1.5)
abline(v=rf.ntree, lwd=2, lty=2)
# dev.off()
```

### Final model

```{r}
set.seed(111)
rf.opt <- randomForest(x=dat.train[,-target], y=as.factor(dat.train[,target]),
                       xtest=dat.test[,-target], ytest=as.factor(dat.test[,target]),
                       importance=TRUE, ntree=rf.ntree)
```

Final random forest metrics

```{r}
sum(diag(rf.opt$confusion))/nrow(dat.train)
sum(diag(rf.opt$test$confusion))/nrow(dat.test)

first.metrics(dat.train[,target], as.numeric(as.character(rf.opt$predicted)),
              dat.test[,target], as.numeric(as.character(rf.opt$test$predicted)))
```

### Variable importance

```{r}
# pdf("./plots/vip-rf-apple.pdf")
varImpPlot(rf.opt, type=1, pch=19, pt.cex=1.5, cex.main=1.5, main="Variable importance")
# dev.off()
# importance(rf, type=1)
```



## AdaBoost

```{r}
library(ada)
```

```{r}
# decision stump
ada.stump <- rpart.control(maxdepth=1, cp=-1, minsplit=0, xval=0)
# bigger depth
ada.depth <- rpart.control(maxdepth=10, cp=-1, maxcompete=1, xval=0)

str(rpart.control())
str(ada.stump)
str(ada.depth)
```


### Base learners

```{r}
auto.tree <- function(depths, plot=FALSE) {
  tree.metrics <- matrix(NA, length(depths), 2)
  colnames(tree.metrics) <- c("Train err", "Test err")
  rownames(tree.metrics) <- rep(NA, length(depths))

  i <- 1
  for (d in depths) {
    rownames(tree.metrics)[i] <- paste0("d=", d)

    control <- rpart.control(maxdepth=d, cp=-1, minsplit=0, xval=0)
    tree <- rpart(Outcome ~ ., data=dat.train, method="class", control=control)

    if (plot) {rpart.plot(tree)}

    tree.train <- accuracy.score(dat.train$Outcome, predict(tree, type="class"))
    tree.test <- accuracy.score(dat.test$Outcome,
                                predict(tree, type="class",
                                        newdata=dat.test[,-target]))

    tree.metrics[i,] <- c(1 - tree.train, 1 - tree.test)
    i <- i + 1
  }

  return(tree.metrics)
}
```

```{r}
# weak.err <- auto.tree(c(1,2,3), TRUE)

weak.err <- tree.cv(1, dat.train, formula(Outcome ~ .), target)
weak.err
```


### Boost the trees

```{r}
auto.ada <- function(params, M=1000, plot=FALSE, metrics=FALSE) {
  # params: {depth, nu, bag.frac}
  combos <- dim(params)[1]  # number of combinations

  ## Training error
  ada.train.err <- matrix(NA, M, combos)
  colnames(ada.train.err) <- rep(NA, combos)

  ## Test error
  ada.cv.err <- matrix(NA, M, combos)
  colnames(ada.cv.err) <- rep(NA, combos)

  for (combo in 1:combos) {
    colnames(ada.train.err)[combo] <- paste0("Train (", paste0(params[combo,], collapse=","), ")")
    colnames(ada.cv.err)[combo] <- paste0("CV (", paste0(params[combo,], collapse=","), ")")

    d <- params[combo,1]  # weak learner depth
    nu <- params[combo,2]  # shrinkage
    bag <- params[combo,3]  # subsampling fraction

    if (d > 1) {
      control <- rpart.control(maxdepth=d, cp=-1, maxcompete=1, xval=0)
    } else {
      control <- rpart.control(maxdepth=d, cp=-1, minsplit=0, xval=0)
    }

    set.seed(111)
    adaboost <- ada::ada(x=as.matrix(dat.train[,-target]), y=dat.train[,target],
                         test.x=as.matrix(dat.test[,-target]), test.y=dat.test[,target],
                         loss="exponential", type="discrete", iter=M,
                         nu=nu, bag.frac=bag, control=control)

    ada.cv <- adaboost.cv(M, dat.train, 5, target, control=control, lam=nu, bag=bag)

    if (plot) {plot(adaboost, FALSE, TRUE)}

    ada.train.err[,combo] <- adaboost$model$errs[,1]
    ada.cv.err[,combo] <- ada.cv

  }

  if (metrics) {
    for (combo in 1:combos) {
      M <- which.min(ada.cv.err[,combo])

      print(paste0("AdaBoost (", paste0(params[combo,], collapse=","), "), ", "M*: ", M))
      print(paste0("Train error: ", ada.train.err[M,combo]))
      print(paste0("CV error: ", ada.cv.err[M,combo]))
    }
  }

  return(cbind(ada.train.err, ada.cv.err))
}
```

Fix one hyperparameter then choose another one, show shrinkage influence. Keep the base learner depth fixed first

#### Decision stump tuning

Tune the shrinkage

```{r}
ada.err1 <- auto.ada(matrix(c(1, 1, 1,
                              1, 0.1, 1),
                            ncol=3, byrow=TRUE), plot=FALSE, metrics=TRUE)
```

Tune the shrinkage with subsampling fraction

```{r}
ada.err2 <- auto.ada(matrix(c(1, 1, 0.5,
                              1, 0.1, 0.5),
                            ncol=3, byrow=TRUE), plot=FALSE, metrics=TRUE)
```

Considerare che le performance del subsampling sono influenzate dal seed. In un contesto reale andrebbe fatta una simulazione per vedere l'errore medio

Siccome tra nu=1 e nu=0.1 cambia poco in termini di CV error si sceglie nu=1 che impiega molte meno iterazioni
Considerando anche che il dataset è bilanciato, rallentare il learning non influisce molto

In letteratura non viene evidenziata un'esplicita dipendenza dei parametri, ci si può permettere di fare una grid search

- Lo shrinkage rallenta il processo di learning
- Il subsampling abbassa il CV error

```{r}
# pdf("./plots/biasvar-ada1-apple.pdf")
plot.ada(cbind(ada.err1[,-c(1,2)], ada.err2[,-c(1,2)]), main="Bias-Variance tradeoff d=1")
# dev.off()
```

#### Tree with depth tuning

Tune the shrinkage

```{r}
ada.err3 <- auto.ada(matrix(c(10, 1, 1,
                              10, 0.1, 1),
                            ncol=3, byrow=TRUE), plot=FALSE, metrics=TRUE)
```

Tune the shrinkage with subsampling fraction

```{r}
ada.err4 <- auto.ada(matrix(c(10, 1, 0.5,
                              10, 0.1, 0.5),
                            ncol=3, byrow=TRUE), plot=FALSE, metrics=TRUE)
```

I subsampling migliora notevolmente le performance dello shrinkage, combinare questi due parametri ha grande influenza sulle performance

Aumentare la profondità degli alberi implica, in questo caso, un maggior numero di iterazioni, ma non è vero in generale

```{r}
# pdf("./plots/biasvar-ada2-apple.pdf")
plot.ada(cbind(ada.err3[,-c(1,2)], ada.err4[,-c(1,2)]), main="Bias-Variance tradeoff d=10")
# dev.off()
```



### Final model

AdaBoost with decision stumps

```{r}
set.seed(111)
adaboost.opt1 <- ada::ada(x=as.matrix(dat.train[,-target]),
                         y=dat.train[,target],
                         test.x=as.matrix(dat.test[,-target]),
                         test.y=dat.test[,target],
                         loss="exponential", type="discrete",
                         iter=901, nu=0.1, bag.frac=0.5,
                         control=ada.stump)
```

AdaBoost with base learner of greater depth

```{r}
set.seed(111)
adaboost.opt2 <- ada::ada(x=as.matrix(dat.train[,-target]),
                         y=dat.train[,target],
                         test.x=as.matrix(dat.test[,-target]),
                         test.y=dat.test[,target],
                         loss="exponential", type="gentle",
                         iter=252, nu=0.1, bag.frac=0.5,
                         control=ada.depth)
```

```{r}
summary(adaboost.opt1)
summary(adaboost.opt2)

# plot(adaboost.opt, FALSE, TRUE)
# plot(adaboost.opt2, FALSE, TRUE)
```

```{r}
first.metrics(dat.train$Outcome,
              predict(adaboost.opt1, newdata=dat.train, type="vector"),
              dat.test$Outcome,
              predict(adaboost.opt1, newdata=dat.test, type="vector"))

first.metrics(dat.train$Outcome,
              predict(adaboost.opt2, newdata=dat.train, type="vector"),
              dat.test$Outcome,
              predict(adaboost.opt2, newdata=dat.test, type="vector"))
```


### Variable importance

Variable importance for decision stump

```{r}
boost.avgvip1 <- adaboost.vip(target, dat.train, 1, 901, 0.1, 0.5)
boost.avgvip1 <- sort(boost.avgvip1)
```

Variable importance for bigger trees

```{r}
boost.avgvip2 <- adaboost.vip(target, dat.train, 10, 152, 0.1, 0.5)
boost.avgvip2 <- sort(boost.avgvip2)
```

```{r}
pdf("./plots/vip-ada1-apple.pdf")
plot.ada.vip(boost.avgvip1, main="Average variable importance d=1")
dev.off()

pdf("./plots/vip-ada2-apple.pdf")
plot.ada.vip(boost.avgvip2, main="Average variable importance d=10")
dev.off()
```





## Super learner

Learners:
- `SL.mean`
- `SL.randomForest`
- `SL.knn`
- `SL.rpart`
- `SL.rpartPrune`
- `SL.glmnet`
- `SL.gbm`??

```{r}
library(SuperLearner)
library(parallel)
```

Define learners

```{r}
## random forest
my.rf <- create.Learner("SL.randomForest", list(ntree=rf.ntree), name_prefix="RF")
## kNN
my.knn <- create.Learner("SL.knn", list(k=k.cross), name_prefix="kNN")
## decision tree
my.dt <- create.Learner("SL.rpart", list(minsplit=20, cp=0, xval=5), name_prefix="DT")
## decision tree with pruning
my.dtpr <- create.Learner("SL.rpartPrune", list(minsplit=20, cp=0, xval=5), name_prefix="DTpr")
## ridge, lasso and elastic-net logistic regression
my.log <- create.Learner("SL.glmnet", tune=list(alpha=c(0, 1, 0.5)), detailed_names=T, name_prefix="Log")

myLibrary <- c(my.knn$names, my.rf$names, my.dt$names, my.dtpr$names,
               my.log$names)
myLibrary2 <- c(my.rf$names, my.dt$names, my.dtpr$names,
               my.log$names)

str(my.rf)
str(my.knn)
str(my.dt)
str(my.dtpr)
str(my.log)
```

### Discrete super learners

#### Mean

Mean over all observations

```{r}
set.seed(111)
sl.mean <- SuperLearner(Y=dat.train[,target],
                        X=dat.train[,-target], family=binomial(),
                        SL.library=c("SL.mean"),
                        cvControl=list(V=10, shuffle=FALSE))
```

```{r}
print(sl.mean)

first.metrics(dat.train[,target], ifelse(predict(sl.mean, dat.train[,-target])$pred>=0.5, 1, 0),
              dat.test[,target], ifelse(predict(sl.mean, dat.test[,-target])$pred>=0.5, 1, 0))
```

#### Random forest

Grow a random forest

```{r}
set.seed(111)  # when shuffle=TRUE and for randomForest
sl.rf <- SuperLearner(Y=dat.train[,target],
                      X=dat.train[,-target], family=binomial(),
                      SL.library=my.rf$names,
                      cvControl=list(V=10, shuffle=FALSE))

str(sl.rf$fitLibrary$SL.randomForest$object, max.level=1)
```

```{r}
print(sl.rf)

first.metrics(dat.train[,target], ifelse(sl.rf$SL.predict>=0.5, 1, 0),
              dat.test[,target], ifelse(predict(sl.rf, dat.test[,-target])$pred>=0.5, 1, 0))
```

#### kNN

```{r}
set.seed(111)
sl.knn <- SuperLearner(Y=dat.train[,target],
                       X=dat.train[,-target], family=binomial(),
                       SL.library=my.knn$names,
                       cvControl=list(V=10, shuffle=FALSE))

str(sl.knn$fitLibrary$SL.knn_1_All, max.level=1)
```

```{r}
print(sl.knn)

first.metrics(dat.train[,target], ifelse(sl.knn$SL.predict>=0.5, 1, 0),
              dat.test[,target],
              ifelse(predict(sl.knn, dat.test[,-target], dat.train[,-target], dat.train[,target],
                             onlySL=TRUE)$pred>=0.5, 1, 0))
```

#### Decision tree with pruning

```{r}
set.seed(111)
sl.dt <- SuperLearner(Y=dat.train[,target],
                      X=dat.train[,-target], family=binomial(),
                      SL.library=my.dtpr$names,
                      cvControl=list(V=10, shuffle=FALSE))

# str(sl.dt$fitLibrary$SL.rpartPrune_1_All$object, max.level=1)
```

```{r}
print(sl.dt)

first.metrics(dat.train[,target], ifelse(sl.dt$SL.predict>=0.5, 1, 0),
              dat.test[,target], ifelse(predict(sl.dt, dat.test[,-target])$pred>=0.5, 1, 0))
```


### The super learner

#### Full super learner

```{r}
cluster = parallel::makeCluster(4)

parallel::clusterSetRNGStream(cluster, iseed=111)
foo <- parallel::clusterEvalQ(cluster, library(SuperLearner))
parallel::clusterExport(cluster, myLibrary)

(sl.full <- snowSuperLearner(Y=dat.train[,target], X=dat.train[,-target],
                             family=binomial(), cluster=cluster, SL.library=myLibrary,
                             cvControl=list(V=10, shuffle=FALSE)))
sl.final$times$everything

parallel::stopCluster(cluster)
```

Diagnostic

```{r}
print(sl.full)

dotchart(sort(sl.full$coef),
         main="Learners influence", pch=19, xlab="Coefficient", pt.cex=1.5,
         col=ifelse(sort(sl.full$coef)==0, "red", "black"))
```

```{r}
sl.full.pred <- predict(sl.full, dat.test[,-target], dat.train[,-target], dat.train[,target])

first.metrics(dat.train[,target], ifelse(sl.full$SL.predict>=0.5, 1, 0),
              dat.test[,target], ifelse(sl.full.pred$pred>=0.5, 1, 0))
```

Cross-validate the strong learners

```{r}
cluster = parallel::makeCluster(4)

parallel::clusterSetRNGStream(cluster, iseed=111)
foo <- parallel::clusterEvalQ(cluster, library(SuperLearner))
parallel::clusterExport(cluster, myLibrary)

system.time({
  sl.full.cv <- CV.SuperLearner(Y=dat.train[,target], X=dat.train[,-target],
                                family=binomial(), parallel=cluster, SL.library=myLibrary,
                                cvControl=list(V=5), innerCvControl=list(list(V=10, shuffle=FALSE)))
})

summary(sl.full.cv)

parallel::stopCluster(cluster)
```

```{r}
plot(sl.full.cv) + theme_bw()
```



#### Reduced super learner

```{r}
cluster = parallel::makeCluster(4)

parallel::clusterSetRNGStream(cluster, iseed=111)
foo <- parallel::clusterEvalQ(cluster, library(SuperLearner))
parallel::clusterExport(cluster, myLibrary2)

(sl.final <- snowSuperLearner(Y=dat.train[,target], X=dat.train[,-target], family=binomial(),
                              cluster=cluster, SL.library=c("SL.mean", myLibrary2),
                              cvControl=list(V=10, shuffle=FALSE)))
sl.final$times$everything

stopCluster(cluster)
```

```{r}
print(sl.final)

# pdf("./plots/coef-sl-apple.pdf")
dotchart(sort(sl.final$coef),
         main="Learners influence", pch=19, xlab="Coefficient", pt.cex=1.5,
         col=ifelse(sort(sl.final$coef)==0, "red", "black"), cex.main=1.5)
# dev.off()
# abline(v=0, lty=2, lwd=2)
```

```{r}
sl.final.pred <- predict(sl.final, dat.test[,-target], dat.train[,-target], dat.train[,target])

first.metrics(dat.train[,target], ifelse(sl.final$SL.predict>=0.5, 1, 0),
              dat.test[,target], ifelse(sl.final.pred$pred>=0.5, 1, 0))
```

Cross-validate the strong learners

```{r}
cluster = parallel::makeCluster(4)

parallel::clusterSetRNGStream(cluster, iseed=111)
foo <- parallel::clusterEvalQ(cluster, library(SuperLearner))
parallel::clusterExport(cluster, myLibrary)

system.time({
  sl.final.cv <- CV.SuperLearner(Y=dat.train[,target], X=dat.train[,-target],
                                family=binomial(), parallel=cluster, SL.library=myLibrary,
                                cvControl=list(V=5), innerCvControl=list(list(V=10, shuffle=FALSE)))
})

summary(sl.final.cv)

parallel::stopCluster(cluster)
```

```{r}
plot(sl.final.cv) + theme_bw()
```

























